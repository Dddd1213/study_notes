# BI面试

[TOC]

## 你的项目中使用了哪些技术栈？请分别介绍一下 Spring Boot、Redis、RabbitMQ 在项目中的作用。

- SpringBoot：项目快速构建，快速整合Mybatis等依赖
- Mybatis（Plus)：数据库操作，Mybatis（plus）中提供了一些基本的增删改查方法，可以加快开发速率
- Redis：
  - 结合SpringCache对已生成图表进行了缓存，提高加载速度
  - Redisson中自带的工具类实现了令牌桶方式的ip限流
- RabbitMQ：消息队列。在项目中用于对AIGC生成图表进行异步化处理
  - 具体：用户提交图表后，先将原始图表存入数据库，设置状态，将任务放入消息队列中，处理完成后再更新状态。
  - 设置了死信队列，把超时的、异常的任务交给死信队列再次处理



## 你是如何使用 AIGC 来生成指定格式的？请简述整个过程

- 对接了一个类似chatgpt的第三方ai平台
- 编写prompt，预设ai的角色、输入内容和生成结果的格式
- 对prompt进行调试，直到ai能够稳定生成结果

## 你给 AI 预设的 Prompt 结构是什么样的？如何优化 Prompt？

- 预设
  - 指定ai的角色
  - 指定数据输入格式：分为分析需求和原始数据两部分
  - 指定输出格式：分为Echart图表代码和数据分析结论，为了方便后续分割，我采用连续多个【 进行隔断
- 优化
  - 指定一组示例回答



## 你是如何保证用户上传的数据文件的安全性的？

- 对上传的文件进行校验
  - 文件类型校验：从MutipartFile获取文件名，分割文件的后缀名，检查是否为excel类型
  - 文件大小限制：限制不能超过1MB等
- 严格校验
  - 文件内的格式校验：用户可能自行修改文件后缀名，可以匹配特定格式文件的开头或结尾来校验
  - 文件内容安全：采用第三方服务比如腾讯云数据万象等，防止用户上传敏感信息



## 什么是限流？有哪些常见的限流算法？

- 通过限制单用户的访问频率，或者某方法的访问频率，来防止一些恶意攻击和系统过载，从而保证系统的稳定性。
- 固定窗口：固定时间只能允许固定数量访问，但是在窗口的边界处可能会出现瞬间的高负载情况
- 滑动窗口：设置一个滑动周期，比如每隔5s窗口就像后滑动一定范围，可以缓解边界高负载情况，但是难以选择合适的滑动单位
- 漏桶限流：设置桶容量和固定速率，一固定速率处理请求，如果桶容量满了就拒绝请求
- 令牌桶限流：以固定速率生成令牌，执行该操作前先要获取令牌，拿到令牌的人才能操作



## 什么是 Redisson？它在项目中具体如何实现分布式限流？你的限流策略是什么？

- 是一个开源的java redis客户端，提供了一些redis的便捷操作接口，比如分布式锁、分布式队列等

- 这里用redisson中的rateLimiter实现了对单个用户生成图表操作的限流

- 具体

  - 创建RedisLimiterManager类，对限流器进行集中管理

  - 写一个doRateLimit方法，传入key，在里面定义令牌生成的速度和每个操作使用几个令牌等信息（这里可以区分会员和普通用户），如果拿不到令牌则抛出异常

  - 在用户上传图表的方法中调用doRateLimit类，传入方法名+用户id作为key

    

## 什么是分库分表？为什么你选择对每份原始数据进行分表存储？有什么优缺点？

- 分库分表是一种数据库架构设计方法，通过将单一的数据库划分为多个子数据库（分库）和多个表（分表），将数据进行分散存储，从而提高查询性能、扩展性和负载均衡，解决大规模数据存储和查询的性能问题。


- 分库分表的缺点是会增加项目和架构的复杂性，如果业务涉及关联查询、跨分表查询，查询逻辑会变得更加复杂。




## 什么是同步和异步？什么是阻塞和非阻塞？

- 同步和异步：关注消息的通知机制
- 阻塞和非阻塞：关注线程等待消息通知时的状态



## 什么是线程池？自定义参数？

- 线程池是一种用于管理和复用线程的机制，它允许在应用程序中创建一组可用线程，并在需要执行任务时将任务分配给这些线程。


- 参数
  - 核心线程数：线程池中一直保持活动的线程数，相当于公司的固定员工
  - 最大线程数：线程池中允许存在的最大线程数，相当于叫完外包之后的最大人数
  - 空闲线程存活时间：超过核心线程数的线程如果在这段时间内都不被使用，就会被销毁
  - 阻塞队列：用于存放等待执行任务的队列，一般用无界。
  - 线程工厂：用于创建线程的工厂。
  - 拒绝策略：当线程池无法接受新的任务时，会采取指定的线程策略。

- 该任务需要等待第三方 AI 接口的返回，需要消耗较长的时间，在这期间不需要高强度的 CPU 计算。将核心线程数设置得更大。



## 分布式消息队列有哪些应用场景？

分布式消息队列的作用是将消息从一个发送者传递给一个或多个接收者，从而实现解耦、异步、可靠的系统通信。

常见的应用场景有：

1）应用解耦：解耦系统内的不同模块，使它们能够独立开发、部署和扩展。一个模块可以将消息发送到队列，而其他模块则可以异步地接收并处理这些消息，而**不需要直接调用模块的 API**。 

2）**异步处理**：可以将耗时的任务作为消息放入消息队列中，然后由单个或多个工作线程来处理，从而提高系统性能和响应速度。 

3）**流量削峰**：当系统面临突发的高峰流量时，分布式消息队列可以通过请求排队的方式实现流量的平滑处理，防止系统过载。 

4）日志和监控：分布式消息队列可以高效地收集和传输日志数据、监控数据和指标数据，这是 Kafka 的一个典型应用场景。

5）**跨语言和跨平台通信**：分布式消息队列通常提供多语言和多平台的客户端，因此可以用于不同编程语言和操作系统之间的通信，本质上也是应用解耦。

6）分布式事务：有些分布式消息队列支持分布式事务，可以用于确保消息的可靠传递和处理，同时保持一致性。 

在本项目中，使用 RabbitMQ 消息队列来对耗时的 AI 生成任务进行异步化处理，同时可以解耦创建任务和执行任务模块，在系统负载增大时，可以开启多个任务执行服务，用轮训的方式消费消息、并发处理任务。



## 你在项目中为什么使用分布式消息队列来存储任务消息？ 

- 分布式存储：消息存储在分布式的消息队列中而不是本地，有利于**分布式系统的扩展**。

- 提高系统可靠性：分布式消息队列通常会保证消息的可靠传递，确保消息不会丢失，未即时处理的任务可以在消费者准备好时再次处理。 


- 高可扩展性：使用分布式消息队列，可以轻松地添加多个任务消费者，**提高系统的并发处理能力。**


- 任务重试：分布式消息队列通常支持消息的重试机制。如果某个任务由于某种原因未能成功处理，消息队列可以重新将其推送给消费者，直到成功为止。


在本项目中，使用了 RabbitMQ 的消息确认机制，只有接受消息并处理成功的情况下，才会确认消息；否则拒绝消息并通过死信队列进行降级处理（比如修改任务状态为失败）。通过这种机制，可以确保每一个任务都被系统处理，不会出现丢失。

## 为什么使用 RabbitMQ 这个消息队列？它相比于其他的消息队列有哪些优点和缺点？

（背诵类题目，可以加主观回答）

- 在选用 RabbitMQ 消息队列前，我做过充分的技术选型和调研。发现 RabbitMQ 不仅简单易用（通过阅读官方文档就能上手开发），而且其时效性极低（延迟最低，微秒级）。此外，RabbitMQ 支持消息确认机制、延迟队列、死信队列等特性，能够满足业务对于消息可靠性的需求，这是我选择它的原因。


## RabbitMQ 有哪几种交换机？你在项目中选择了哪个交换机？

RabbitMQ 主要有 4 种交换机：

- Direct Exchange（直连交换机）：根据消息的路由键（Routing Key）将消息发送到与之完全匹配的队列上。通常用于点对点通信。
- Fanout Exchange（广播交换机）：将收到的消息发送到所有与之绑定的队列上，忽略路由键。通常用于广播消息给多个消费者。
- Topic Exchange（主题交换机）：根据消息的路由键和绑定队列的通配符模式来进行匹配，将消息发送到符合匹配规则的队列上。通常用于支持灵活的消息路由、相对复杂的业务场景。
- Headers Exchange（头交换机）：根据消息的头部信息来进行匹配，将消息发送到符合匹配规则的队列上。这种方式用的不多，适用于基于消息头部信息进行路由、相对复杂的业务场景。

我在项目中使用了 Direct 类型的交换机，因为项目只有 1 种生产者、1 组消费者、1 种消息类型，选用 Direct 交换机的点对点通信已经能够满足需求，且便于理解。

## 这个项目的性能是否有遇到瓶颈？如何优化项目？

1）由于 OpenAI 的 API QPS 有限，项目实际运行时出现了调用超限的报错，所以我们需要通过限流、或者增加负载均衡（轮询调用多个 OpenAI 账号）的方式来保证系统的稳定性。
2）由于 OpenAI 单次能处理的数据量有限，所以我们需要通过数据格式压缩，来让系统同时处理更多行列的数据。如果发现压缩效果差，可以优化算法；如果发现压缩效率低，可以用文件分片 + 并发压缩。
3）由于 AI 响应时间较长，用户要等待很久，我们需要将同步等待优化为异步执行，能立刻给用户提交成功的提示，从而在提高用户体验的同时，支持更多用户使用系统
4）随着用户图表数的增多，可能前端查询速度会越来越慢，这时就需要通过缓存来优化查询性能。











